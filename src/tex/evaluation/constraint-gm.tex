% !TEX root = ../../main.tex
\section{ConstraintGM}%
\label{sec:eval.cgm}

ConstraintGM is a \ac{DSL} developed with the shared goal of tackling \ac{GC}
problem specification using a \ac{TPL} (Racket, to be precise).  This solution
heavily and blindly relied on Maxima~\cite{Maxima:2021:Maxima}, a generic
\ac{CAS} to solve \ac{GC} problems.  Geometric entities were boiled down to
their algebraic equation representation coupled with a set of the problems
constraints and delivered to Maxima.  Maxima would then attempt to solve the
problem and return a result that was parsed and presented to the user.

This approach came at a severe performance cost.  Not only as the communication
between ConstraintGM and Maxima slow, lest we forget that Maxima is a
\emph{generic} solver.  Per a suggestion, this lead to an \texttt{impromptu}
implementation of some \ac{GC} problem solutions, creating what was called the
\ac{GFL}. The latter approach revealed that contextually specialized solutions
had a greater potential than relying on a generic solver.

It is worth noting that relying on Maxima meant ConstraintGM was intrinsically
exact and robust since symbolic \ac{GCS} methods, used by Maxima, don't suffer
from such issues.  The \ac{GFL}, when compared to the Maxima-based approach, is
more fragile in that regard because it will depend on the underlying constructs'
number type.  If an exact arbitrary precision number type is used, the issue
disappears, but at a performance cost since arbitrary precision arithmetic is
computationally heavy.  Relying on inexact number types can eventually lead to
erroneous results if one is not careful and avoids error-inducing computations,
but, by contrast, offers better performance.  That said, some computations are
unavoidable, such as the computation of the squared root, for example, when the
effective distance is necessary to operate with.  In the end, it is a matter of
making a compromise and evaluating which fits the case at end the best.

The project's benchmark involve three different \ac{GC} problems focused around
object intersection, namely
\begin{enumerate*}[label= (\arabic*)]
  \item line-line intersection,
  \item circle-line intersection, and
  \item circle-circle intersection.
\end{enumerate*}
These problems expanded into thirteen different scenarios that consisted of
rearranging the geometric entities' disposition in order to evaluate the
intersection operation's results and measure each individual scenario's
performance.

We measured real execution time instead of \ac{CPU} time both for ConstraintGM
and our solution.  We ran ConstraintGM's benchmarks a total of nine times to
obtain a relatively decent sample of results, while our solution's benchmarks
were aided by \texttt{BenchmarkTools.jl}~\cite{Chen:2016:BenchmarkTools.jl}, a
package that facilitates benchmarking Julia code tremendously.  The source code
used to benchmark both ConstraintGM and our solution is listed in
\cref{lst:appendix.bench.cgm.rkt,lst:appendix.bench.cgm.jl} respectively.  The
benchmark's results are gathered in \cref{tab:eval.cgm.perf}.  To facilitate
comprehension, these are also plotted in \cref{fig:eval.cgm.perf}.

\begin{table}[htb]
  \caption[ConstraintGM performance benchmarks]{\label{tab:eval.cgm.perf}%
    Performance comparison between ConstraintGM's solutions, both using Maxima
    and \ac{GFL}, and our solution.}
  \footnotesize\centering
  \begin{tabular*}{\linewidth}{r*{3}{l}l}
    \toprule
    \multirow{2}{*}{\textbf{Scenario}}
    & \multicolumn{3}{c}{\textbf{Execution time ($\mathrm{mean}\pm\sigma$)}}
    & \multirow{2}{*}{\textbf{GC problem}} \\
    & \multicolumn{1}{c}{\textbf{Maxima}}
    & \multicolumn{1}{c}{\textbf{GFL}}
    & \multicolumn{1}{c}{\textbf{Our solution}} & \\
    \midrule
     1 & \texttt{~2.265 s ± 142.344 ms}
       & \texttt{~8.778 ms ± ~~1.641 ms}
       & \texttt{362.191 μs ± ~4.841 ms}
       & \multirow{2}{*}{Line $\cap$ Line}\\
     2 & \texttt{~1.645 s ± 197.824 ms}
       & \texttt{~6.222 ms ± 440.959 μs}
       & \texttt{159.567 μs ± ~4.634 μs} &\\
    \midrule
     3 & \texttt{~3.958 s ± 295.673 ms}
       & \texttt{~9.444 ms ± ~~1.333 ms}
       & \texttt{~~1.871 ms ± ~4.892 ms} 
       & \multirow{3}{*}{Circle $\cap$ Line}\\
     4 & \texttt{~3.070 s ± 243.768 ms}
       & \texttt{~8.000 ms ± ~~0.000 ns}
       & \texttt{955.815 μs ± ~3.710 ms} &\\
     5 & \texttt{~1.839 s ± ~84.460 ms}
       & \texttt{~6.000 ms ± ~~0.000 ns}
       & \texttt{600.386 μs ± 19.807 μs} &\\
    \midrule
     6 & \texttt{~1.311 s ± ~59.139 ms}
       & \texttt{~5.111 ms ± 333.333 μs}
       & \texttt{241.531 μs ± 12.504 μs} 
       & \multirow{8}{*}{Circle $\cap$ Circle}\\
     7 & \texttt{~1.847 s ± ~50.466 ms}
       & \texttt{~5.333 ms ± 500.000 μs}
       & \texttt{242.780 μs ± ~5.692 μs} &\\
     8 & \texttt{~1.868 s ± ~37.650 ms}
       & \texttt{~5.333 ms ± 500.000 μs}
       & \texttt{245.425 μs ± 11.840 μs} &\\
     9 & \texttt{~4.277 s ± ~37.053 ms}
       & \texttt{~5.222 ms ± 440.959 μs}
       & \texttt{515.829 μs ± ~4.881 ms} &\\
    10 & \texttt{~2.506 s ± 238.696 ms}
       & \texttt{~7.222 ms ± 440.959 μs}
       & \texttt{629.341 μs ± ~5.360 ms} &\\
    11 & \texttt{~3.493 s ± 258.715 ms}
       & \texttt{~7.222 ms ± 440.959 μs}
       & \texttt{~~1.453 ms ± ~5.070 ms} &\\
    12 & \texttt{~3.830 s ± 150.402 ms}
       & \texttt{~9.444 ms ± 527.046 μs}
       & \texttt{~~1.455 ms ± ~5.088 ms} &\\
    13 & \texttt{11.111 s ± ~81.302 ms}
       & \texttt{10.222 ms ± ~~1.093 ms}
       & \texttt{~~1.463 ms ± ~5.055 ms} &\\
    \bottomrule
  \end{tabular*}
\end{table}

Immediately, we can see the disparity between the approach reliant on Maxima
when compared to both the \ac{GFL} and our solution, which was to be expected.
Even so, amidst relatively consistent results, scenario 13 made Maxima slug more
than usual.  That scenario consists of two circles intersecting at two different
points, illustrated in \cref{fig:eval.cgm.perf.13}.  It is not the only scenario
of the set that involves two circles that intersect.  However, this is the one
that produces relatively more complex results, which could justify why Maxima
took relatively longer to compute the solution than it did for the scenarios
that preceded this one.

\begin{figure}[htb]
  \begin{subfigure}[t]{.6\linewidth}
    \centering
    \begin{tikzpicture}
    \begin{semilogyaxis}[cgm,
      title={Maxima vs. GFL vs. Our solution},
      xlabel={Scenarios},
      ylabel={Average Time (ns, log)},
      width={\linewidth},
      height=5cm,
      ymax=1e12,
      legend columns=-1,
    ]
      \addplot+ table {data/cgm-maxima.csv};
      \addplot+ table {data/cgm-gfl.csv};
      \addplot+ [color=green] table {data/jlcgal.csv};
      \legend{Maxima,GFL,Our solution}
    \end{semilogyaxis}
    \end{tikzpicture}
    \subcaption{Multi-series plot of every approaches' benchmark results.  N.B.:
      The Y-axis is logarithmic.}\label{fig:eval.cgm.perf.plot}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{.35\linewidth}
    \resizebox{!}{5cm}{
    \begin{tikzpicture}
      \tkzDefPoints{0/0/A,1/1/B}
      \tkzDrawCircle[R](A, 1.5cm)\tkzGetLength{rA}
      \tkzDrawCircle[R](B, 1cm)  \tkzGetLength{rB}
      \tkzInterCC[R](A,\rA pt)(B,\rB pt) \tkzGetPoints{C}{D}
      \tkzDrawPoints[color=red](C,D)
    \end{tikzpicture}}
    \subcaption{Scenario 13 of ConstraintGM's set of benchmarks.}%
    \label{fig:eval.cgm.perf.13}
  \end{subfigure}
  \caption[ConstraintGM benchmarks and Scenario 13]{\label{fig:eval.cgm.perf}%
    ConstraintGM benchmark results collected from \cref{tab:eval.cgm.perf} in a
    multi-series plot in \subref{fig:eval.cgm.perf.plot} beside the depiction
    of scenario 13 from the benchmark in \subref{fig:eval.cgm.perf.13}.}
\end{figure}

Analyzing the results further, we can see our solution also outdoes
ConstraintGM's \ac{GFL}.  This is most likely due to the fact that we are
relying on \ac{CGAL}, a library implemented in C++.  The latter in turn is
notoriously known for being a high performance language, potentially
outperforming Racket.  Nevertheless, there is some overhead in the form of
Julia, but the results are still positive, on average beating the \ac{GFL} by an
order of magnitude.

However, some of our solution's results deviate around a thousand times more
than others, fluctuating from mild micro-second deviations to variations in the
millisecond range.  \Cref{fig:eval.cgm.perferr} illustrates this phenomenon more
clearly.  Looking back at the scenarios where the error is wider, a pattern
starts to emerge as those scenarios are the ones where the participating objects
intersect.  In other words, objects are being created.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
  \begin{axis}[cgm,
    title={GFL vs. Our solution},
    xlabel={Scenarios},
    ylabel={Average Time (ns)},
    ymax=1.2e7,
    width={.9\linewidth},
    height=6cm,
    enlarge y limits={.2},
    legend columns=-1
  ]
    \addplot+ table [y error=std] {data/cgm-gfl.csv};
    \addplot+ table [y error=std] {data/jlcgal.csv};

    \legend{GFL,Our solution}
  \end{axis}
  \end{tikzpicture}
  \caption[GFL vs. Our solution]{\label{fig:eval.cgm.perferr}% A slightly more
    A detailed comparison between the \ac{GFL} and our solution alone, 
    additionally representing the standard deviation.}
\end{figure}

It seems object creation takes a toll on our solution efficiency despite clear
performance gains on average.  This is probably related to the complexity and
superior dimension of \ac{CGAL}'s primitive geometric objects when compared to
the ones used by the \ac{GFL}.  Examining our solution's more detailed benchmark
results (see \cref{lst:appendix.cgmdata.jl}), we can see more information about
how much time is consumed during garbage collection, and estimates on the amount
of memory used and how many allocations were performed.

Every scenario that produced objects also shows garbage collection involvement
in some sense.  In some of the worst cases, nearly half of the time is spent
collecting objects.  But garbage collection in such scenarios is to be expected,
and on average, typically no more than one tenth of the time is spent in garbage
collection.  It could still be noticeable, but at this scale, it seems
negligible.  Ironically, ConstraintGM's \ac{GFL} did not spend any time in
garbage collection (see \cref{lst:appendix.cgmdata.rkt}), though our sample size
is tremendously smaller than that produced by the benchmark runs using
\texttt{BenchmarkTools.jl}.  This could also be once again related to the
difference in complexity of the objects being created by the \ac{GFL} and our
solution.

One of the great features \texttt{BenchmarkTools.jl} has is its capability of
also producing a histogram of the samples it collected.  Looking over at these
problematic scenarios, the histograms show an accumulation of samples towards
the faster run times, leaving some crumbs spread out.  This is consistent with
the scenarios' respectively greater standard deviation values.

In conclusion, our solution proves capable and performant, having surpassed
ConstraintGM's \ac{GFL} by an entire order of magnitude on average.  The
downside is the potential yet seemingly rare slower computations when we are
creating lots of objects which could prove problematic.  However, upon further
observation, we can conclude that a vast majority of the time that is not the
case and such situations where computation is in fact impacted are rare.  Even
then, the impact seems negligible as well.
